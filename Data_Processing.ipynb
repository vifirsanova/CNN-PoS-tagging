{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Processing",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRNmwJ70hHSZoBVTTxQg2m"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3OJhPisvWdf"
      },
      "source": [
        "### **Dataset processing**\n",
        "\n",
        "Tokenization, building a training vocabulary, tags extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k405_6OGuNbQ"
      },
      "source": [
        "# Downlad train and test sets from SynTagRus\r\n",
        "\r\n",
        "train = pyconll.load_from_file('/content/ru_syntagrus-ud-train.conllu')\r\n",
        "test = pyconll.load_from_file('/content/ru_syntagrus-ud-dev.conllu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRCTruuCvjUY"
      },
      "source": [
        "\r\n",
        "A training data sample:\r\n",
        "\r\n",
        "```\r\n",
        "Несерьезно как-то …\r\n",
        "Савельев объяснил , что вышла замуж за диктора районного радиоузла .\r\n",
        "Муж настоял , чтобы она бросила работу .\r\n",
        "Вскоре после этого стало известно , что у диктора где-то в деревне остались жена и ребенок .\r\n",
        "И Ефимова развелась , \" И , по-моему , правильно сделала \" , - добавил Савельев .\r\n",
        "- А тебе известно , что она уже пол года не работает ?\r\n",
        "Это Савельеву известно не было .\r\n",
        "- Ну вот , - сказал Семен Еремеевич .\r\n",
        "- Надо изучать своих работников .\r\n",
        "- Да ты бери ее , бери ! - закричал Савельев .\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxUgITTFv518"
      },
      "source": [
        "### **Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y9d4c0pf9FQ"
      },
      "source": [
        "import re\n",
        "\n",
        "# Use RegEx to process the data\n",
        "# Leave only letters and/or digits\n",
        "\n",
        "tokens = re.compile(r'[\\w\\d]+')\n",
        "\n",
        "# Texts to lower case \n",
        "# Find all the sequences of words and/or digits\n",
        "# Set the minimum size of a token\n",
        "\n",
        "def tokenizer(text, min_token_size = n):\n",
        "    text = text.lower()\n",
        "    all_tokens = tokens.findall(txt)\n",
        "    return [token for token in all_tokens if len(token) >= min_token_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-U6D1UYzrtU"
      },
      "source": [
        "Token types:\r\n",
        "\r\n",
        "* fake padding token '__PAD__'\r\n",
        "* standard token for letter sequences (word) \r\n",
        "* numeric token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-KUdLHEzBh1"
      },
      "source": [
        "Tokens sample (char level):\r\n",
        "\r\n",
        "```\r\n",
        "[('<PAD>', 0), (' ', 1), ('о', 2), ('е', 3), ('а', 4), ('т', 5), ('и', 6), ('н', 7), ('.', 8), ('с', 9)]\r\n",
        "```\r\n",
        "Tags list:\r\n",
        "\r\n",
        "```\r\n",
        "<NOTAG> ADJ ADP ADV AUX CCONJ DET INTJ NOUN NUM PART PRON PROPN PUNCT SCONJ SYM VERB X\r\n",
        "```\r\n"
      ]
    }
  ]
}