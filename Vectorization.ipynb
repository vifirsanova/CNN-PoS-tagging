{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vectorization",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1FxX4pR8r2thmK+8w+w21"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD61Uu3u4-yL"
      },
      "source": [
        "### **Vectorization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpa6oV1igKn4"
      },
      "source": [
        "# Transform texts and tags for train and test sets into matrices of vectors\n",
        "\n",
        "train_texts, train_tags = corpus_to_tensor(train, char_vocab, tags_ids, max_sentences_len, max_token_len)\n",
        "train_set = TensorDataset(train_texts, train_tags)\n",
        "\n",
        "test_texts, test_tags = corpus_to_tensor(test, char_vocab, tags_ids, max_sentences_len, max_token_len)\n",
        "test_set = TensorDataset(test_texts, test_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3qbH2h9rLSh"
      },
      "source": [
        "A transformed text sample. This will be used for the model training.\r\n",
        "\r\n",
        "```\r\n",
        "tensor([[ 0, 39,  4, 25,  4, 11, 20,  7,  6, 13,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\r\n",
        "        [ 0,  2, 23, 11,  4,  9,  5,  7,  2, 22,  2,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\r\n",
        "        [ 0, 17, 16, 10,  4, 12, 11,  3,  7,  6, 19,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\r\n",
        "        [ 0,  9, 12, 19, 21,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\r\n",
        "        [ 0, 40,  3, 15,  3,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\r\n",
        "```\r\n",
        "\r\n",
        "A transformed tag sample. This will be used for the model training.\r\n",
        "\r\n",
        "```\r\n",
        "tensor([ 8,  1,  8,  8, 12, 12,  4,  8,  1, 13, 16,  2,  8,  3,  3, 13, 16,  2,\r\n",
        "         8,  2,  8,  5,  3, 10, 16,  2,  8,  8,  2,  8, 13,  8, 13, 13,  0,  0,\r\n",
        "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\r\n",
        "         0,  0,  0,  0,  0,  0,  0])\r\n",
        "```"
      ]
    }
  ]
}